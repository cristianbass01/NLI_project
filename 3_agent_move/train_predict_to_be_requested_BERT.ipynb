{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "os.makedirs('saved_models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MLP(37).cuda() # Replace model instantiation with another class here (SVC for example) if wishing to test other models\n",
    "# model = XGBClassifier(n_estimators = 300, max_depth = 13, learning_rate = 0.01)\n",
    "# model = XGBClassifier(n_estimators = 100, max_depth = 39 * 2, learning_rate = 0.01)\n",
    "# model = SVC(C = 1, kernel = 'rbf', gamma = 'scale')\n",
    "# TODO: somehting is wrong since the dict-based model achieves 0.30 accuracy\n",
    "# and it only encounters 30/3000 not previously seen examples in the test set\n",
    "# so it should have a 0.99 accuracy\n",
    "TRANSFORMER_MODEL_NAME = 'bert-base-uncased'\n",
    "SAVE_MODEL_SUFFIX = '1'\n",
    "save_model_name = TRANSFORMER_MODEL_NAME.split('/')[-1]\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "nr_features = 768\n",
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "epochs = 5\n",
    "patience = 2\n",
    "class_weight_beta = 0.999\n",
    "use_class_weights = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_intent_list(intent_list):\n",
    "    intents = set()\n",
    "    if len(intent_list) == 0:\n",
    "        intents.add('other')\n",
    "    for intent in intent_list:\n",
    "        if intent.startswith('Restaurant'):\n",
    "            intents.add(intent)\n",
    "        elif intent.startswith('Hotel'):\n",
    "            intents.add(intent)\n",
    "        elif intent.startswith('Booking'):\n",
    "            intents.add(intent)\n",
    "        elif intent.startswith('general'):\n",
    "            intents.add(intent)\n",
    "        else:\n",
    "            intents.add('other')\n",
    "    # print(f'Original {intent_list}')\n",
    "    # print(f'Modified {list(intents)}')\n",
    "    return list(intents)\n",
    "\n",
    "def process_service_list(service_list):\n",
    "    services = set()\n",
    "    if len(service_list) == 0:\n",
    "        services.add('other')\n",
    "    for service in service_list:\n",
    "        if service == 'restaurant':\n",
    "            services.add('restaurant')\n",
    "        elif service == 'hotel':\n",
    "            services.add('hotel')\n",
    "        else:\n",
    "            services.add('other')\n",
    "        if len(services) == 3:\n",
    "            break\n",
    "    return list(services)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_split(dataset, split):\n",
    "    df = dataset[split].to_pandas()\n",
    "    new_df = pd.DataFrame(columns = df.columns)\n",
    "    for i in range(len(df)):\n",
    "        # Taken from notebook, to know which lines to skip\n",
    "        row = df.loc[i]\n",
    "        if not any(set(row.turns['frames'][turn_id]['service']).intersection(['hotel', 'restaurant']) for turn_id,utt in enumerate(row.turns['utterance'])):\n",
    "            continue\n",
    "        \n",
    "        new_df.loc[len(new_df)] = row\n",
    "        # new_df.loc[len(new_df) - 1]['services'] = process_service_list(new_df.loc[len(new_df) - 1]['services'])\n",
    "        # for i, frame_service in [frame['service'] for frame in df.loc[i].turns['frames']]:\n",
    "            # df.loc[i].turns['frames']\n",
    "    return new_df\n",
    "\n",
    "def extract_to_be_retrieved_info(dataset, limit_nothing = False, limit_nothing_count = 200):\n",
    "    user_act_types_list = []\n",
    "    user_slots_per_act_type_list = []\n",
    "    to_be_retrieved_list = []\n",
    "    tokens_list = []\n",
    "    to_be_requested_list = []\n",
    "    \n",
    "    nothing_count = 0\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        turns = dataset.loc[i].turns\n",
    "        for j, (utterance, speaker, dialogue_act, frames) in enumerate(zip(turns['utterance'], turns['speaker'], turns['dialogue_acts'], turns['frames'])):\n",
    "            # if speaker != 1:\n",
    "                # continue\n",
    "            # Skip using dialogue act intents\n",
    "            # print(dialogue_act['dialog_act']['act_type'])\n",
    "            # if 'other' in process_intent_list(dialogue_act['dialog_act']['act_type']):\n",
    "                # continue\n",
    "            # Skip using frame services\n",
    "            # if 'other' in process_service_list(frames['service']):\n",
    "                # continue\n",
    "            services = frames['service']\n",
    "            if speaker == 0:\n",
    "                user_utterance = utterance\n",
    "                current_booking_service = [service for service in services if service in [\"hotel\", \"restaurant\"]]\n",
    "                \n",
    "            act_types = dialogue_act['dialog_act']['act_type']\n",
    "            act_slots = dialogue_act['dialog_act']['act_slots']\n",
    "            \n",
    "            # if speaker == 1 and not any(act_type.startswith(\"Hotel\") or act_type.startswith(\"Restaurant\") or act_type.startswith(\"Booking\") for act_type in act_types):\n",
    "            #     user_act_types_list.pop()\n",
    "            #     user_slots_per_act_type_list.pop()\n",
    "            #     continue\n",
    "            \n",
    "            # print(act_types)\n",
    "            # if speaker == 0:\n",
    "            #     if len([1 for act_type in dialogue_act['dialog_act']['act_type'] if act_type.startswith('general')]) == len(dialogue_act['dialog_act']['act_type']):\n",
    "            #         skip_bot = True\n",
    "            #         continue\n",
    "                    \n",
    "            #     if 'other' in process_intent_list(dialogue_act['dialog_act']['act_type']):\n",
    "            #         skip_bot = True\n",
    "            #         continue\n",
    "            #     if 'other' in process_intent_list(turns['dialogue_acts'][j + 1]['dialog_act']['act_type']):\n",
    "            #         skip_bot = True\n",
    "            #         continue\n",
    "            #     skip_bot = False\n",
    "            # else:\n",
    "            #     if skip_bot:\n",
    "            #         continue\n",
    "            if speaker == 0:\n",
    "                skip_bot = False\n",
    "                if not any(da.startswith(\"Hotel\") or da.startswith(\"Restaurant\") or da.startswith(\"Booking\") for da in act_types):\n",
    "                    skip_bot = True\n",
    "                    continue\n",
    "            elif skip_bot:\n",
    "                    continue\n",
    "            \n",
    "            # print(act_slots)\n",
    "            # print(act_types)\n",
    "            slots_per_act_type = []\n",
    "            to_be_retrieved = set()\n",
    "            to_be_requested = set()\n",
    "            for act_type, slots in zip(act_types, act_slots):\n",
    "                slot_names = slots['slot_name']\n",
    "                slot_values = slots['slot_value']\n",
    "                \n",
    "                domain = act_type.split('-')[0].lower()\n",
    "                if domain == 'booking' and len(current_booking_service)==1:\n",
    "                    domain = current_booking_service[0]\n",
    "                \n",
    "                # to_be_retrieved.add(domain + '-availability')\n",
    "                \n",
    "                # if 'hotel' in domain or 'restaurant' in domain:\n",
    "                if speaker == 0: # When it's the user's turn\n",
    "                    for slot_name, slot_value in zip(slot_names, slot_values):\n",
    "                        if slot_name != 'none':\n",
    "                            slots_per_act_type.append(act_type.lower() + '-' + slot_name + ':' + slot_value)\n",
    "                elif domain in [\"hotel\", \"restaurant\", \"booking\", \"general\"]: # When it's the bot's turn\n",
    "                    act_type_relevant_slots = [(slot_name, slot_value) for slot_name, slot_value in zip(slot_names, slot_values) if slot_value != '?' and slot_name != 'none']\n",
    "                    to_be_retrieved.update(set([domain + '-' + slot_name + ':' + slot_value for slot_name, slot_value in act_type_relevant_slots]))\n",
    "                    \n",
    "                    if len(to_be_retrieved) != 0 and any((slot_name_value.split(\":\")[0]!=domain+\"-none\" for slot_name_value in to_be_retrieved)) and not \"-No\" in act_types:\n",
    "                        to_be_retrieved.add(domain + '-availability:yes')\n",
    "                    elif \"-No\" in act_types:\n",
    "                        to_be_retrieved.add(domain + '-availability:no')\n",
    "                    \n",
    "                    to_be_requested_relevant_slots = [(slot_name, slot_value) for slot_name, slot_value in zip(slot_names, slot_values) if slot_value == '?' and slot_name != 'none']\n",
    "                    to_be_requested.update(set([domain + '-' + slot_name for slot_name, _ in to_be_requested_relevant_slots]))\n",
    "                \n",
    "            if speaker == 0: # When it's the user's turn\n",
    "                user_act_types_list.append(act_types)\n",
    "                user_slots_per_act_type_list.append(slots_per_act_type)\n",
    "                \n",
    "                # nr += 1\n",
    "                # print(nr)\n",
    "                # print(\"Input:\", slots_per_act_type)\n",
    "            else: # When it's the bot's turn\n",
    "                # if limit_nothing and len(to_be_requested) == 0:\n",
    "                #     if nothing_count == limit_nothing_count:\n",
    "                #         continue\n",
    "                #     nothing_count += 1\n",
    "                \n",
    "                if len(to_be_requested) == 0:\n",
    "                    to_be_requested.add('NOTHING')\n",
    "                \n",
    "                to_be_retrieved_list.append(list(to_be_retrieved))\n",
    "                to_be_requested_list.append(list(to_be_requested))\n",
    "                \n",
    "                # print(act_types)\n",
    "                \n",
    "                user_slots_per_act_type = user_slots_per_act_type_list[-1]\n",
    "                to_be_retrieved = to_be_retrieved_list[-1]\n",
    "                \n",
    "                input_text = user_utterance + ' | USER SLOTS PER ACT' + ', '.join(user_slots_per_act_type) + ' | RETRIEVED SLOTS' + ', '.join(to_be_retrieved)\n",
    "                # print(\"INPUT TEXT:\", input_text)\n",
    "                \n",
    "                # print(\"TO BE REQ:\", to_be_requested)\n",
    "                \n",
    "                tokenized = transformer_tokenizer(input_text, padding = 'max_length')\n",
    "                tokens_list.append(tokenized)\n",
    "                \n",
    "            \n",
    "    return tokens_list, to_be_requested_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('multi_woz_v22')\n",
    "\n",
    "try:\n",
    "    train\n",
    "    print(\"Dataset already loaded, moving on\")\n",
    "except:\n",
    "    train = preprocess_split(dataset, 'train')\n",
    "    test = preprocess_split(dataset, 'test')\n",
    "    val = preprocess_split(dataset, 'validation')\n",
    "    train_embeddings_list, train_to_be_requested_list = extract_to_be_retrieved_info(train)\n",
    "    test_embeddings_list, test_to_be_requested_list = extract_to_be_retrieved_info(test)\n",
    "    val_embeddings_list, val_to_be_requested_list = extract_to_be_retrieved_info(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer().fit(train_to_be_requested_list)\n",
    "pickle.dump(mlb, open('saved_models/MOVE_AGENT_REQ_mlb.pkl', 'wb'))\n",
    "# input_mlb = MultiLabelBinarizer().fit(train_user_slots_per_act_type_list)\n",
    "print(mlb.classes_)\n",
    "\n",
    "train_input = train_embeddings_list\n",
    "train_output = mlb.transform(train_to_be_requested_list)\n",
    "\n",
    "test_input = test_embeddings_list\n",
    "test_output = mlb.transform(test_to_be_requested_list)\n",
    "\n",
    "val_input = val_embeddings_list\n",
    "val_output = mlb.transform(val_to_be_requested_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_class = [0] * len(mlb.classes_)\n",
    "for act_types in train_to_be_requested_list:\n",
    "    for act_type in act_types:\n",
    "        for i, class_ in enumerate(mlb.classes_):\n",
    "            if class_ in act_type:\n",
    "                samples_per_class[i] += 1\n",
    "        # samples_per_class[np.argmax(mlb.transform([[act_type]]))] += 1\n",
    "\n",
    "print(\"Class counts:\")\n",
    "print([*zip(mlb.classes_, samples_per_class)])\n",
    "\n",
    "samples_per_class = np.array(samples_per_class)\n",
    "\n",
    "effective_num = 1.0 - np.power(class_weight_beta, samples_per_class)\n",
    "class_weights = (1.0 - class_weight_beta) / effective_num\n",
    "class_weights = class_weights / np.sum(class_weights) * len(mlb.classes_)\n",
    "print(\"Class weights:\")\n",
    "print([*zip(mlb.classes_, class_weights)])\n",
    "class_weights = torch.Tensor(class_weights).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify_tokens_tags(tokens_list, encoded_agent_tags_list, batch_size):\n",
    "    ids_batch = []\n",
    "    mask_batch = []\n",
    "    useful_pos_batch = []\n",
    "    labels_batch = []\n",
    "    \n",
    "    if encoded_agent_tags_list is None:\n",
    "        encoded_agent_tags_list = range(len(tokens_list))\n",
    "    \n",
    "    for tokens, agent_encoded_tags in zip(tokens_list, encoded_agent_tags_list):\n",
    "        ids_batch.append(tokens.input_ids)\n",
    "        mask_batch.append(tokens.attention_mask)\n",
    "        labels_batch.append(agent_encoded_tags)\n",
    "        \n",
    "        if len(ids_batch) == batch_size:\n",
    "            yield torch.Tensor(ids_batch).long().cuda(), torch.Tensor(mask_batch).cuda(), torch.Tensor(labels_batch).cuda()\n",
    "            ids_batch.clear()\n",
    "            mask_batch.clear()\n",
    "            labels_batch.clear()\n",
    "    \n",
    "    yield torch.Tensor(ids_batch).long().cuda(), torch.Tensor(mask_batch).cuda(), torch.Tensor(labels_batch).cuda()\n",
    "    return None\n",
    "\n",
    "def compute_loss(transformer, tokens_list, encoded_agent_tags_list, batch_size, criterion):\n",
    "    transformer.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for ids_batch, mask_batch, labels_batch in batchify_tokens_tags(tokens_list, encoded_agent_tags_list, batch_size):\n",
    "            out = transformer.forward(input_ids = ids_batch, attention_mask = mask_batch)\n",
    "            \n",
    "            # logits_useful, labels_useful = outputs_keep_useful_part(out.logits, labels_batch, useful_pos_batch)\n",
    "            logits_useful = out.logits\n",
    "            labels_useful = labels_batch\n",
    "            \n",
    "            loss = criterion(logits_useful, labels_useful)\n",
    "            losses.append(loss.item())\n",
    "    transformer.train()\n",
    "    return np.mean(losses)\n",
    "\n",
    "def predict(transformer, tokens, batch_size):\n",
    "    transformer.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for ids_batch, mask_batch, _ in batchify_tokens_tags(tokens, None, batch_size):\n",
    "            out = transformer.forward(input_ids = ids_batch, attention_mask = mask_batch)\n",
    "            res = (out.logits > 0).cpu().detach().numpy()\n",
    "            predictions.append(res)\n",
    "    return np.concatenate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = AutoModelForSequenceClassification.from_pretrained(TRANSFORMER_MODEL_NAME, num_labels = len(mlb.classes_), ignore_mismatched_sizes = True, problem_type = \"multi_label_classification\").cuda()\n",
    "transformer.train()\n",
    "\n",
    "if use_class_weights:\n",
    "    criterion = nn.BCEWithLogitsLoss(weight = class_weights)\n",
    "else:\n",
    "    criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(transformer.parameters(), lr = learning_rate)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "waited = 0\n",
    "\n",
    "min_val_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_train_loss = []\n",
    "    \n",
    "    for ids_batch, mask_batch, labels_batch in batchify_tokens_tags(train_input, train_output, batch_size):\n",
    "        optim.zero_grad()\n",
    "        out = transformer.forward(input_ids = ids_batch, attention_mask= mask_batch)\n",
    "        \n",
    "        loss = criterion(out.logits, labels_batch)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        epoch_train_loss.append(loss.item())\n",
    "    \n",
    "    epoch_train_loss = np.mean(epoch_train_loss)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    epoch_val_loss = compute_loss(transformer, val_input, val_output, batch_size, criterion)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}: Train loss = {epoch_train_loss}, Val loss = {epoch_val_loss}\")\n",
    "    \n",
    "    if epoch_val_loss < min_val_loss:\n",
    "        min_val_loss = epoch_val_loss\n",
    "        transformer.save_pretrained('saved_models/MOVE_AGENT_REQ_' + save_model_name + '_' + SAVE_MODEL_SUFFIX)\n",
    "        \n",
    "    \n",
    "    if len(val_losses) != 0 and val_losses[-1] <= epoch_val_loss:\n",
    "        waited += 1\n",
    "        if waited > patience:\n",
    "                val_losses.append(epoch_val_loss)\n",
    "                break\n",
    "    else:\n",
    "        waited = 0\n",
    "    \n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = AutoModelForSequenceClassification.from_pretrained('saved_models/MOVE_AGENT_REQ_' +  save_model_name + '_' + SAVE_MODEL_SUFFIX, num_labels = len(mlb.classes_)).cuda()\n",
    "\n",
    "predicted_output = predict(transformer, test_input, batch_size)\n",
    "\n",
    "acc = accuracy_score(test_output, predicted_output)\n",
    "report = classification_report(test_output, predicted_output, target_names = mlb.classes_, digits = 3)\n",
    "print(report)\n",
    "print(f'acc = {acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
