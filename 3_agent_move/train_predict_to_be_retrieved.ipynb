{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import string\n",
    "import fasttext\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "from dict_model import DictModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input, epochs = 100, batch_size = 64, patience = 2, lr = 1e-3):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.BatchNorm1d(input),\n",
    "            nn.Linear(input, input),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input, 100),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.patience = patience\n",
    "        self.lr = lr\n",
    "    \n",
    "    def compute_loss(self, X, y, criterion):\n",
    "        self.eval()\n",
    "        batch_size = self.batch_size\n",
    "        N = X.shape[0]\n",
    "        batches = [(X[(i - batch_size) : (i if i < N else N - 1), :], y[(i - batch_size) : (i if i < N else N - 1)]) for i in range(batch_size, N + batch_size, batch_size)]\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            for batch, y_true in batches:\n",
    "                y_pred = self.forward(batch)\n",
    "                loss = criterion(y_pred, y_true)\n",
    "                losses.append(loss.item())\n",
    "        self.train()\n",
    "        return np.mean(losses)\n",
    "    \n",
    "    def fit(self, X, y, X_val, y_val):\n",
    "        X = torch.Tensor(X).cuda()\n",
    "        y = torch.Tensor(y).cuda()\n",
    "        X_val = torch.Tensor(X_val).cuda()\n",
    "        y_val = torch.Tensor(y_val).cuda()\n",
    "\n",
    "        self.head = nn.Linear(50, y.shape[1]).cuda()\n",
    "        batch_size = self.batch_size\n",
    "        optim = torch.optim.Adam(self.parameters(), lr = self.lr)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        N = X.shape[0]\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        waited = 0\n",
    "        \n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            batches = [(X[(i - batch_size) : (i if i < N else N - 1), :], y[(i - batch_size) : (i if i < N else N - 1)]) for i in range(batch_size, N + batch_size, batch_size)]\n",
    "            epoch_train_loss = []\n",
    "            for batch, y_true in batches:\n",
    "                y_pred = self.forward(batch)\n",
    "                loss = criterion(y_pred, y_true)\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                epoch_train_loss.append(loss.item())\n",
    "            \n",
    "            epoch_train_loss = np.mean(epoch_train_loss)\n",
    "            train_losses.append(epoch_train_loss)\n",
    "            \n",
    "            epoch_val_loss = self.compute_loss(X_val, y_val, criterion)\n",
    "            if len(val_losses) != 0 and val_losses[-1] <= epoch_val_loss:\n",
    "                waited += 1\n",
    "                if waited > self.patience:\n",
    "                    break\n",
    "            else:\n",
    "                waited = 0\n",
    "\n",
    "            val_losses.append(epoch_val_loss)\n",
    "            \n",
    "            \n",
    "        return train_losses, val_losses\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.head(self.mlp(X))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = torch.Tensor(X).cuda()\n",
    "        y = self.forward(X)\n",
    "        return (y > 0.5).float().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MLP(37).cuda() # Replace model instantiation with another class here (SVC for example) if wishing to test other models\n",
    "# model = XGBClassifier(n_estimators = 300, max_depth = 13, learning_rate = 0.01)\n",
    "# model = XGBClassifier(n_estimators = 100, max_depth = 39 * 2, learning_rate = 0.01)\n",
    "# model = SVC(C = 1, kernel = 'rbf', gamma = 'scale')\n",
    "# TODO: somehting is wrong since the dict-based model achieves 0.30 accuracy\n",
    "# and it only encounters 30/3000 not previously seen examples in the test set\n",
    "# so it should have a 0.99 accuracy\n",
    "model = DictModel()\n",
    "# model = SVC(C = 0.1, kernel = 'rbf', gamma = 'scale') # 50.2 % accuracy\n",
    "\n",
    "normalize_inputs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_intent_list(intent_list):\n",
    "    intents = set()\n",
    "    if len(intent_list) == 0:\n",
    "        intents.add('other')\n",
    "    for intent in intent_list:\n",
    "        if intent.startswith('Restaurant'):\n",
    "            intents.add(intent)\n",
    "        elif intent.startswith('Hotel'):\n",
    "            intents.add(intent)\n",
    "        elif intent.startswith('Booking'):\n",
    "            intents.add(intent)\n",
    "        elif intent.startswith('general'):\n",
    "            intents.add(intent)\n",
    "        else:\n",
    "            intents.add('other')\n",
    "    # print(f'Original {intent_list}')\n",
    "    # print(f'Modified {list(intents)}')\n",
    "    return list(intents)\n",
    "\n",
    "def process_service_list(service_list):\n",
    "    services = set()\n",
    "    if len(service_list) == 0:\n",
    "        services.add('other')\n",
    "    for service in service_list:\n",
    "        if service == 'restaurant':\n",
    "            services.add('restaurant')\n",
    "        elif service == 'hotel':\n",
    "            services.add('hotel')\n",
    "        else:\n",
    "            services.add('other')\n",
    "        if len(services) == 3:\n",
    "            break\n",
    "    return list(services)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_split(dataset, split):\n",
    "    df = dataset[split].to_pandas()\n",
    "    new_df = pd.DataFrame(columns = df.columns)\n",
    "    for i in range(len(df)):\n",
    "        # Taken from notebook, to know which lines to skip\n",
    "        row = df.loc[i]\n",
    "        if not any(set(row.turns['frames'][turn_id]['service']).intersection(['hotel', 'restaurant']) for turn_id,utt in enumerate(row.turns['utterance'])):\n",
    "            continue\n",
    "        \n",
    "        new_df.loc[len(new_df)] = row\n",
    "        # new_df.loc[len(new_df) - 1]['services'] = process_service_list(new_df.loc[len(new_df) - 1]['services'])\n",
    "        # for i, frame_service in [frame['service'] for frame in df.loc[i].turns['frames']]:\n",
    "            # df.loc[i].turns['frames']\n",
    "    return new_df\n",
    "\n",
    "def extract_to_be_retrieved_info(dataset):\n",
    "    user_act_types_list = []\n",
    "    user_slots_per_act_type_list = []\n",
    "    to_be_retrieved_list = []\n",
    "    \n",
    "    nr = 0\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        turns = dataset.loc[i].turns\n",
    "        for j, (utterance, speaker, dialogue_act, frames) in enumerate(zip(turns['utterance'], turns['speaker'], turns['dialogue_acts'], turns['frames'])):\n",
    "            # if speaker != 1:\n",
    "                # continue\n",
    "            # Skip using dialogue act intents\n",
    "            # print(dialogue_act['dialog_act']['act_type'])\n",
    "            # if 'other' in process_intent_list(dialogue_act['dialog_act']['act_type']):\n",
    "                # continue\n",
    "            # Skip using frame services\n",
    "            # if 'other' in process_service_list(frames['service']):\n",
    "                # continue\n",
    "            services = frames['service']\n",
    "            current_booking_service = [service for service in services if service in [\"hotel\", \"restaurant\"]]\n",
    "                \n",
    "            act_types = dialogue_act['dialog_act']['act_type']\n",
    "            act_slots = dialogue_act['dialog_act']['act_slots']\n",
    "            \n",
    "            print(act_types)\n",
    "            if speaker == 0:\n",
    "                if 'other' in process_intent_list(dialogue_act['dialog_act']['act_type']):\n",
    "                    skip_bot = True\n",
    "                    continue\n",
    "                if 'other' in process_intent_list(turns['dialogue_acts'][j + 1]['dialog_act']['act_type']):\n",
    "                    skip_bot = True\n",
    "                    continue\n",
    "                skip_bot = False\n",
    "            else:\n",
    "                if skip_bot:\n",
    "                    continue\n",
    "            \n",
    "            # if speaker == 0:\n",
    "            #     skip_bot = False\n",
    "            #     if not any(da.startswith(\"Hotel\") or da.startswith(\"Restaurant\") or da.startswith(\"Booking\") for da in act_types):\n",
    "            #         skip_bot = True\n",
    "            #         continue\n",
    "            # elif skip_bot:\n",
    "            #         continue\n",
    "            \n",
    "            # print(act_slots)\n",
    "            # print(act_types)\n",
    "            slots_per_act_type = []\n",
    "            to_be_retrieved = set()\n",
    "            for act_type, slots in zip(act_types, act_slots):\n",
    "                slot_names = slots['slot_name']\n",
    "                slot_values = slots['slot_value']\n",
    "                \n",
    "                domain = act_type.split('-')[0].lower()\n",
    "                if domain == 'booking' and len(current_booking_service)==1:\n",
    "                    domain = current_booking_service[0]\n",
    "                \n",
    "                # if 'hotel' in domain or 'restaurant' in domain:\n",
    "                if domain in ['hotel', 'restaurant', 'booking', 'general']:\n",
    "                    if speaker == 0: # When it's the user's turn\n",
    "                        for slot_name in slot_names:\n",
    "                            if slot_name != 'none':\n",
    "                                slots_per_act_type.append(act_type.lower() + '-' + slot_name)\n",
    "                    else: # When it's the bot's turn\n",
    "                        act_type_relevant_slots = [(slot_name, slot_value) for slot_name, slot_value in zip(slot_names, slot_values) if slot_value != '?' and 'choice' not in slot_name and slot_name != 'none']\n",
    "                        to_be_retrieved.update(set([domain + '-' + slot_name for slot_name, _ in act_type_relevant_slots]))\n",
    "                \n",
    "            if speaker == 0: # When it's the user's turn\n",
    "                user_act_types_list.append(act_types)\n",
    "                user_slots_per_act_type_list.append(slots_per_act_type)\n",
    "                # nr += 1\n",
    "                # print(nr)\n",
    "                # print(\"Input:\", slots_per_act_type)\n",
    "            else: # When it's the bot's turn\n",
    "                to_be_retrieved_list.append(list(to_be_retrieved))\n",
    "                # print(\"Output:\", list(to_be_retrieved))\n",
    "                \n",
    "            \n",
    "            \n",
    "    return user_act_types_list, user_slots_per_act_type_list, to_be_retrieved_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: multi_woz_v22/v2.2_active_only\n",
      "Found cached dataset multi_woz_v22 (/home/adrian/.cache/huggingface/datasets/multi_woz_v22/v2.2_active_only/2.2.0/6719c8b21478299411a0c6fdb7137c3ebab2e6425129af831687fb7851c69eb5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f9ef788c704dedb5fa804db43cdcaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already loaded, moving on\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('multi_woz_v22')\n",
    "\n",
    "try:\n",
    "    train\n",
    "    print(\"Dataset already loaded, moving on\")\n",
    "except:\n",
    "    train = preprocess_split(dataset, 'train')\n",
    "    test = preprocess_split(dataset, 'test')\n",
    "    val = preprocess_split(dataset, 'validation')\n",
    "    train_user_act_types_list, train_user_slots_per_act_type_list, train_to_be_retrieved_list = extract_to_be_retrieved_info(train)\n",
    "    test_user_act_types_list, test_user_slots_per_act_type_list, test_to_be_retrieved_list = extract_to_be_retrieved_info(test)\n",
    "    val_user_act_types_list, val_user_slots_per_act_type_list, val_to_be_retrieved_list = extract_to_be_retrieved_info(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hotel-inform-area' 'hotel-inform-bookday' 'hotel-inform-bookpeople'\n",
      " 'hotel-inform-bookstay' 'hotel-inform-choice' 'hotel-inform-internet'\n",
      " 'hotel-inform-name' 'hotel-inform-parking' 'hotel-inform-pricerange'\n",
      " 'hotel-inform-stars' 'hotel-inform-type' 'hotel-request-address'\n",
      " 'hotel-request-area' 'hotel-request-internet' 'hotel-request-name'\n",
      " 'hotel-request-parking' 'hotel-request-phone' 'hotel-request-postcode'\n",
      " 'hotel-request-pricerange' 'hotel-request-ref' 'hotel-request-stars'\n",
      " 'hotel-request-type' 'restaurant-inform-area' 'restaurant-inform-bookday'\n",
      " 'restaurant-inform-bookpeople' 'restaurant-inform-booktime'\n",
      " 'restaurant-inform-food' 'restaurant-inform-name'\n",
      " 'restaurant-inform-pricerange' 'restaurant-request-address'\n",
      " 'restaurant-request-area' 'restaurant-request-food'\n",
      " 'restaurant-request-name' 'restaurant-request-phone'\n",
      " 'restaurant-request-postcode' 'restaurant-request-pricerange'\n",
      " 'restaurant-request-ref']\n",
      "['booking-bookday' 'booking-bookpeople' 'booking-bookstay'\n",
      " 'booking-booktime' 'booking-name' 'booking-ref' 'hotel-address'\n",
      " 'hotel-area' 'hotel-internet' 'hotel-name' 'hotel-parking' 'hotel-phone'\n",
      " 'hotel-postcode' 'hotel-pricerange' 'hotel-ref' 'hotel-stars'\n",
      " 'hotel-type' 'restaurant-address' 'restaurant-area' 'restaurant-food'\n",
      " 'restaurant-name' 'restaurant-phone' 'restaurant-postcode'\n",
      " 'restaurant-pricerange' 'restaurant-ref']\n"
     ]
    }
   ],
   "source": [
    "if not isinstance(model, MLP) and not isinstance(model, DictModel):\n",
    "    model = MultiOutputClassifier(model)\n",
    "\n",
    "output_mlb = MultiLabelBinarizer().fit(train_to_be_retrieved_list)\n",
    "input_mlb = MultiLabelBinarizer().fit(train_user_slots_per_act_type_list)\n",
    "pickle.dump(input_mlb, open('saved_models/MOVE_RETR_input_mlb.pkl', 'wb'))\n",
    "pickle.dump(output_mlb, open('saved_models/MOVE_RETR_output_mlb.pkl', 'wb'))\n",
    "\n",
    "print(input_mlb.classes_)\n",
    "print(output_mlb.classes_)\n",
    "\n",
    "train_input = input_mlb.transform(train_user_slots_per_act_type_list)\n",
    "train_output = output_mlb.transform(train_to_be_retrieved_list)\n",
    "\n",
    "test_input = input_mlb.transform(test_user_slots_per_act_type_list)\n",
    "test_output = output_mlb.transform(test_to_be_retrieved_list)\n",
    "\n",
    "val_input = input_mlb.transform(val_user_slots_per_act_type_list)\n",
    "val_output = output_mlb.transform(val_to_be_retrieved_list)\n",
    "\n",
    "if normalize_inputs:\n",
    "    train_input = train_input - 0.5\n",
    "    test_input = test_input - 0.5\n",
    "    val_input = val_input - 0.5\n",
    "\n",
    "if not isinstance(model, MLP):\n",
    "    model.fit(train_input, train_output)\n",
    "    pickle.dump(model, open('saved_models/MOVE_RETR_DICT.pkl', 'wb'))\n",
    "else:\n",
    "    train_losses, val_losses = model.fit(train_input, train_output, val_input, val_output)\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "      booking-bookday      0.200     0.018     0.034       109\n",
      "   booking-bookpeople      0.000     0.000     0.000        94\n",
      "     booking-bookstay      0.274     0.321     0.296        53\n",
      "     booking-booktime      0.212     0.579     0.310        76\n",
      "         booking-name      0.185     0.092     0.123       109\n",
      "          booking-ref      0.535     0.553     0.544       499\n",
      "        hotel-address      0.700     0.337     0.455       104\n",
      "           hotel-area      0.378     0.320     0.346       247\n",
      "       hotel-internet      0.233     0.194     0.211       155\n",
      "           hotel-name      0.431     0.332     0.375       434\n",
      "        hotel-parking      0.452     0.182     0.259       154\n",
      "          hotel-phone      0.633     0.588     0.610        85\n",
      "       hotel-postcode      0.972     0.530     0.686        66\n",
      "     hotel-pricerange      0.265     0.220     0.241       236\n",
      "            hotel-ref      0.000     0.000     0.000         2\n",
      "          hotel-stars      0.247     0.198     0.220       202\n",
      "           hotel-type      0.366     0.309     0.335       324\n",
      "   restaurant-address      0.770     0.427     0.549       157\n",
      "      restaurant-area      0.219     0.106     0.143       303\n",
      "      restaurant-food      0.395     0.334     0.362       332\n",
      "      restaurant-name      0.369     0.359     0.364       412\n",
      "     restaurant-phone      0.986     0.731     0.840        93\n",
      "  restaurant-postcode      0.951     0.637     0.763        91\n",
      "restaurant-pricerange      0.224     0.332     0.268       241\n",
      "       restaurant-ref      0.100     0.667     0.174         3\n",
      "\n",
      "            micro avg      0.396     0.329     0.359      4581\n",
      "            macro avg      0.404     0.335     0.340      4581\n",
      "         weighted avg      0.404     0.329     0.353      4581\n",
      "          samples avg      0.230     0.229     0.211      4581\n",
      "\n",
      "acc = 0.3852214072262972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adrian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted_output = model.predict(test_input)\n",
    "\n",
    "acc = accuracy_score(test_output, predicted_output)\n",
    "report = classification_report(test_output, predicted_output, target_names = output_mlb.classes_, digits = 3)\n",
    "print(report)\n",
    "print(f'acc = {acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
