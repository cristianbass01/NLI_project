{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11e25995",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T16:56:26.269842Z",
     "iopub.status.busy": "2023-12-18T16:56:26.269150Z",
     "iopub.status.idle": "2023-12-18T16:56:26.274144Z",
     "shell.execute_reply": "2023-12-18T16:56:26.273308Z"
    },
    "executionInfo": {
     "elapsed": 2948,
     "status": "ok",
     "timestamp": 1702260859756,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "5AhFCv5N4qLF",
    "outputId": "3378655d-31ce-4255-d976-3442c6876cf0",
    "papermill": {
     "duration": 0.021033,
     "end_time": "2023-12-18T16:56:26.276170",
     "exception": false,
     "start_time": "2023-12-18T16:56:26.255137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Mount Google drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d8eaaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T16:56:26.302424Z",
     "iopub.status.busy": "2023-12-18T16:56:26.301722Z",
     "iopub.status.idle": "2023-12-18T16:56:26.305566Z",
     "shell.execute_reply": "2023-12-18T16:56:26.304735Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1702260859757,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "07QFDivu4xL_",
    "outputId": "93fceb19-c6b9-4fe9-f025-4b4c6b8bde32",
    "papermill": {
     "duration": 0.019171,
     "end_time": "2023-12-18T16:56:26.307506",
     "exception": false,
     "start_time": "2023-12-18T16:56:26.288335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#change current working directory\n",
    "#%cd \"/content/drive/MyDrive/1_dialog_act\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781c82a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T16:56:26.333204Z",
     "iopub.status.busy": "2023-12-18T16:56:26.332849Z",
     "iopub.status.idle": "2023-12-18T16:58:00.833392Z",
     "shell.execute_reply": "2023-12-18T16:58:00.832239Z"
    },
    "executionInfo": {
     "elapsed": 25134,
     "status": "ok",
     "timestamp": 1702260884884,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "srMMIeSg44Mr",
    "outputId": "9aeb0ac7-d027-468f-cb93-205128a04a60",
    "papermill": {
     "duration": 94.51644,
     "end_time": "2023-12-18T16:58:00.836132",
     "exception": false,
     "start_time": "2023-12-18T16:56:26.319692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install accelerate\n",
    "#!pip install datasets\n",
    "#!python3 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c43ab2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T16:58:00.864829Z",
     "iopub.status.busy": "2023-12-18T16:58:00.864460Z",
     "iopub.status.idle": "2023-12-18T16:58:23.579704Z",
     "shell.execute_reply": "2023-12-18T16:58:23.578638Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1702260884884,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "VCMzJGrR4kv3",
    "papermill": {
     "duration": 22.732624,
     "end_time": "2023-12-18T16:58:23.582191",
     "exception": false,
     "start_time": "2023-12-18T16:58:00.849567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mister/miniconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
    "from transformers import AlbertForSequenceClassification, AlbertTokenizer, AlbertConfig\n",
    "from transformers import AdamW\n",
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, Dataset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from torch import cuda\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from itertools import product\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#import nltk\n",
    "\n",
    "#nltk.download('punkt')\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "#sys.path.append(os.path.abspath('../../'))\n",
    "#from util import generate_metrics_latex_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be8e16",
   "metadata": {
    "papermill": {
     "duration": 0.013348,
     "end_time": "2023-12-18T16:58:23.609279",
     "exception": false,
     "start_time": "2023-12-18T16:58:23.595931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f59fe5c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T16:58:23.638745Z",
     "iopub.status.busy": "2023-12-18T16:58:23.637594Z",
     "iopub.status.idle": "2023-12-18T16:58:23.646262Z",
     "shell.execute_reply": "2023-12-18T16:58:23.645342Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1702260884884,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "XHD6GUfLmeEY",
    "papermill": {
     "duration": 0.025667,
     "end_time": "2023-12-18T16:58:23.648502",
     "exception": false,
     "start_time": "2023-12-18T16:58:23.622835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAVE_MODEL_TO_PATH = \"./../saved_models/\"\n",
    "TRAIN_DATA_SAVE_PATH = \"utterances_act_types/train.json\"\n",
    "TEST_DATA_SAVE_PATH = \"utterances_act_types/test.json\"\n",
    "VALID_DATA_SAVE_PATH = \"utterances_act_types/valid.json\"\n",
    "#TRAIN_DATA_SAVE_PATH = \"/kaggle/input/utterances-act-type/train.json\"\n",
    "#TEST_DATA_SAVE_PATH = \"/kaggle/input/utterances-act-type/test.json\"\n",
    "#VALID_DATA_SAVE_PATH = \"/kaggle/input/utterances-act-type/valid.json\"\n",
    "\n",
    "best_model_path = SAVE_MODEL_TO_PATH + '/1_model_dialog_act.pt'\n",
    "\n",
    "#best_model_path = '/kaggle/input/saved-models/1_model_dialog_act.pt'\n",
    "\n",
    "PRETRAINED_MODELS = {\n",
    "    'bert': 'bert-large-uncased',\n",
    "    'roberta': 'roberta-base',\n",
    "    'xlnet': 'xlnet-large-cased',\n",
    "    'xlm': 'xlm-mlm-en-2048',\n",
    "    'distilbert': 'distilbert-base-uncased',\n",
    "    'albert':'albert-base-v2'\n",
    "}\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig),\n",
    "    'albert':(AlbertForSequenceClassification,AlbertTokenizer, AlbertConfig)\n",
    "}\n",
    "\n",
    "# roberta-large too big for our GPU\n",
    "MODEL_TYPE = 'roberta'\n",
    "PRETRAINED_MODEL_NAME = PRETRAINED_MODELS[MODEL_TYPE]\n",
    "\n",
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[MODEL_TYPE]\n",
    "\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "# batch size 64 too big\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Epochs limit, but we have patience = 2 and we save the best model\n",
    "EPOCHS = 50\n",
    "WEIGHT_DECAY = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d4c497c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T16:58:23.678339Z",
     "iopub.status.busy": "2023-12-18T16:58:23.677522Z",
     "iopub.status.idle": "2023-12-18T16:58:23.683213Z",
     "shell.execute_reply": "2023-12-18T16:58:23.682331Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1702260884885,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "Dm-Dm52gmeEa",
    "papermill": {
     "duration": 0.022796,
     "end_time": "2023-12-18T16:58:23.685324",
     "exception": false,
     "start_time": "2023-12-18T16:58:23.662528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_variable_to_json(variable, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(variable, file)\n",
    "\n",
    "def load_variable_from_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        variable = json.load(file)\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd628874",
   "metadata": {
    "papermill": {
     "duration": 0.013277,
     "end_time": "2023-12-18T16:58:23.711830",
     "exception": false,
     "start_time": "2023-12-18T16:58:23.698553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7b15d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T16:58:23.740129Z",
     "iopub.status.busy": "2023-12-18T16:58:23.739392Z",
     "iopub.status.idle": "2023-12-18T16:58:24.158320Z",
     "shell.execute_reply": "2023-12-18T16:58:24.157191Z"
    },
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1702260885335,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "9La38LT64kwA",
    "outputId": "9a32a5db-8163-432f-b24f-1658499bfb47",
    "papermill": {
     "duration": 0.435524,
     "end_time": "2023-12-18T16:58:24.160521",
     "exception": false,
     "start_time": "2023-12-18T16:58:23.724997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from file.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    X_train, y_train = load_variable_from_json(TRAIN_DATA_SAVE_PATH)\n",
    "    X_test, y_test = load_variable_from_json(TEST_DATA_SAVE_PATH)\n",
    "    X_valid, y_valid = load_variable_from_json(VALID_DATA_SAVE_PATH)\n",
    "\n",
    "    print('Data loaded from file.')\n",
    "except:\n",
    "    print('No saved data found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2afe8e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T16:58:24.245592Z",
     "iopub.status.busy": "2023-12-18T16:58:24.245212Z",
     "iopub.status.idle": "2023-12-18T16:58:24.470450Z",
     "shell.execute_reply": "2023-12-18T16:58:24.469514Z"
    },
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1702260885683,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "ExoqLooUFnlJ",
    "outputId": "720850de-7114-4320-cca0-18ee378e47e0",
    "papermill": {
     "duration": 0.242013,
     "end_time": "2023-12-18T16:58:24.472787",
     "exception": false,
     "start_time": "2023-12-18T16:58:24.230774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest utterance length: 119\n",
      "Labels: ['Hotel-Inform', 'Hotel-Request', 'Restaurant-Inform', 'Restaurant-Request', 'general-bye', 'general-greet', 'general-thank', 'other']\n"
     ]
    }
   ],
   "source": [
    "longest_train_data = max(X_train + X_test + X_valid, key=lambda x: len(x.split()))\n",
    "print('Longest utterance length:', len(longest_train_data.split()))\n",
    "\n",
    "num_labels = len(set([act for act_list in y_train for act in act_list ]))\n",
    "\n",
    "all_labels = sorted(set([act for act_list in y_train for act in act_list ]))\n",
    "print('Labels:', all_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73469185",
   "metadata": {
    "papermill": {
     "duration": 0.013306,
     "end_time": "2023-12-18T16:58:24.499993",
     "exception": false,
     "start_time": "2023-12-18T16:58:24.486687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tokenizing and creating dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a35d2967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T16:58:24.528580Z",
     "iopub.status.busy": "2023-12-18T16:58:24.528187Z",
     "iopub.status.idle": "2023-12-18T16:58:24.538648Z",
     "shell.execute_reply": "2023-12-18T16:58:24.537722Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1702260885684,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "2f0mGhIN4kwC",
    "papermill": {
     "duration": 0.027326,
     "end_time": "2023-12-18T16:58:24.540896",
     "exception": false,
     "start_time": "2023-12-18T16:58:24.513570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiLabelBinarizer(classes=[&#x27;Hotel-Inform&#x27;, &#x27;Hotel-Request&#x27;,\n",
       "                             &#x27;Restaurant-Inform&#x27;, &#x27;Restaurant-Request&#x27;,\n",
       "                             &#x27;general-bye&#x27;, &#x27;general-greet&#x27;, &#x27;general-thank&#x27;,\n",
       "                             &#x27;other&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiLabelBinarizer</label><div class=\"sk-toggleable__content\"><pre>MultiLabelBinarizer(classes=[&#x27;Hotel-Inform&#x27;, &#x27;Hotel-Request&#x27;,\n",
       "                             &#x27;Restaurant-Inform&#x27;, &#x27;Restaurant-Request&#x27;,\n",
       "                             &#x27;general-bye&#x27;, &#x27;general-greet&#x27;, &#x27;general-thank&#x27;,\n",
       "                             &#x27;other&#x27;])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiLabelBinarizer(classes=['Hotel-Inform', 'Hotel-Request',\n",
       "                             'Restaurant-Inform', 'Restaurant-Request',\n",
       "                             'general-bye', 'general-greet', 'general-thank',\n",
       "                             'other'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will help us to transform the labels into a one-hot encoded numeric array\n",
    "mlb = MultiLabelBinarizer(classes=list(all_labels))\n",
    "mlb.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b78d293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T16:58:24.571659Z",
     "iopub.status.busy": "2023-12-18T16:58:24.570735Z",
     "iopub.status.idle": "2023-12-18T17:00:46.033439Z",
     "shell.execute_reply": "2023-12-18T17:00:46.031969Z"
    },
    "executionInfo": {
     "elapsed": 2367,
     "status": "ok",
     "timestamp": 1702260888048,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "DxhfkAze4kwC",
    "papermill": {
     "duration": 141.493685,
     "end_time": "2023-12-18T17:00:46.049153",
     "exception": true,
     "start_time": "2023-12-18T16:58:24.555468",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained BERT model and tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(PRETRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81857282",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:23:13.582922Z",
     "iopub.status.idle": "2023-12-18T12:23:13.583276Z",
     "shell.execute_reply": "2023-12-18T12:23:13.583122Z",
     "shell.execute_reply.started": "2023-12-18T12:23:13.583105Z"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1702260888049,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "6COYaAPC4kv9",
    "outputId": "92976648-d165-4d47-bc14-757d3ba3bd39",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max chosen length: 256\n"
     ]
    }
   ],
   "source": [
    "max_length = min(2 ** (len(tokenizer.tokenize(longest_train_data))-1).bit_length(), 512)\n",
    "print('Max chosen length:', max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2e65fe3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.837121Z",
     "iopub.status.idle": "2023-12-18T12:21:50.837511Z",
     "shell.execute_reply": "2023-12-18T12:21:50.837327Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.837310Z"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1702260888049,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "MN90sZDk4kwC",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tokenizer, X, y, max_length):\n",
    "        self.X = X\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        # Fit the label binarizer and transform the labels into one-hot encoded format\n",
    "        self.labels = mlb.fit_transform(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Encode the utterance using the provided tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            self.X[idx],\n",
    "            add_special_tokens=True,\n",
    "            max_length = self.max_length,\n",
    "            return_token_type_ids=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            truncation=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        # Convert the list of strings into a one-hot encoded format\n",
    "        label = self.labels[idx]  # This should now be a binary vector instead of a list of strings\n",
    "        # Return the encoding and the label\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.float),\n",
    "            'token_type_ids': encoding['token_type_ids'].flatten()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09694d7c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.839475Z",
     "iopub.status.idle": "2023-12-18T12:21:50.839820Z",
     "shell.execute_reply": "2023-12-18T12:21:50.839671Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.839654Z"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1702260888049,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "Fk9U0QEK7MNF",
    "outputId": "fa57fa54-edec-414e-f0e4-b0dad9c76e11",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples:  56776\n",
      "Test samples:  7372\n",
      "Valid samples:  7374\n"
     ]
    }
   ],
   "source": [
    "# Smaller dataset to try\n",
    "p = 1\n",
    "n_train_samples = int(len(X_train) * p)\n",
    "n_test_samples = int(len(X_test) * p)\n",
    "n_valid_samples = int(len(X_valid) * p)\n",
    "\n",
    "print(\"Train samples: \", n_train_samples)\n",
    "print(\"Test samples: \", n_test_samples)\n",
    "print(\"Valid samples: \", n_valid_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba1dea75",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.840975Z",
     "iopub.status.idle": "2023-12-18T12:21:50.841305Z",
     "shell.execute_reply": "2023-12-18T12:21:50.841161Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.841145Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1702260888050,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "LABzcmWE4kwC",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(tokenizer, X_train[:n_train_samples], y_train[:n_train_samples], max_length)\n",
    "test_dataset = CustomDataset(tokenizer, X_test[:n_test_samples], y_test[:n_test_samples], max_length)\n",
    "valid_dataset = CustomDataset(tokenizer, X_valid[:n_valid_samples], y_valid[:n_valid_samples], max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be9c3ab6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.842412Z",
     "iopub.status.idle": "2023-12-18T12:21:50.842731Z",
     "shell.execute_reply": "2023-12-18T12:21:50.842585Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.842570Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1702260888050,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "bpoi3YTp7Wew",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58d39274",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.844005Z",
     "iopub.status.idle": "2023-12-18T12:21:50.844328Z",
     "shell.execute_reply": "2023-12-18T12:21:50.844185Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.844170Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1702260888050,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "RgB5SL6JmeEi",
    "outputId": "b1d33474-aab9-4772-8bbd-75ba683994ab",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25cd71d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9084aaac",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.846054Z",
     "iopub.status.idle": "2023-12-18T12:21:50.846407Z",
     "shell.execute_reply": "2023-12-18T12:21:50.846235Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.846219Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1702260888050,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "nqy56vk6meEj",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, mlb):\n",
    "    checkpoint = torch.load(checkpoint_fpath, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    mlb.set_params(**checkpoint['mlb'])\n",
    "    return model, mlb\n",
    "\n",
    "def save_ckp(state, best_model_path):\n",
    "    torch.save(state, best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac3e78e9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.847886Z",
     "iopub.status.idle": "2023-12-18T12:21:50.848355Z",
     "shell.execute_reply": "2023-12-18T12:21:50.848127Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.848106Z"
    },
    "executionInfo": {
     "elapsed": 7284,
     "status": "ok",
     "timestamp": 1702260895328,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "2CZvhR2LmeEj",
    "outputId": "3209ed7e-6a9e-4b41-93b4-b74181fffcb7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model_name, num_labels):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.l1 = model_class.from_pretrained(pretrained_model_name, num_labels=self.num_labels)\n",
    "        self.pre_classifier = torch.nn.Linear(8, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, self.num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        output = output.view(-1, self.num_labels)  # Reshape the output\n",
    "        return output\n",
    "\n",
    "model = BERTClass(PRETRAINED_MODEL_NAME, num_labels)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96d8483f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.849409Z",
     "iopub.status.idle": "2023-12-18T12:21:50.849736Z",
     "shell.execute_reply": "2023-12-18T12:21:50.849590Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.849575Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1702260895328,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "k8FpkZPdmeEk",
    "outputId": "f486842a-7ddf-41e8-9709-e0b0fb3f51df",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mister/miniconda3/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, correct_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fa6bbd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42362842",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.851016Z",
     "iopub.status.idle": "2023-12-18T12:21:50.851319Z",
     "shell.execute_reply": "2023-12-18T12:21:50.851180Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.851166Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid(model, valid_dataloader):\n",
    "    val_targets = []\n",
    "    val_outputs = []\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_dataloader):\n",
    "            input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "            attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "            labels = batch['labels'].to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_targets.extend(labels.cpu().detach().numpy().tolist())\n",
    "            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "            \n",
    "\n",
    "    val_loss /= len(valid_dataloader)\n",
    "    \n",
    "    return val_loss, val_targets, val_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2060cfb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.852550Z",
     "iopub.status.idle": "2023-12-18T12:21:50.852851Z",
     "shell.execute_reply": "2023-12-18T12:21:50.852713Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.852699Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "        attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "        token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "        labels = batch['labels'].to(device, dtype=torch.float)\n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f41d87b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.854138Z",
     "iopub.status.idle": "2023-12-18T12:21:50.854492Z",
     "shell.execute_reply": "2023-12-18T12:21:50.854316Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.854301Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1702260895329,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "yYxcyQT3meEk",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(num_epochs, train_dataloader, valid_dataloader, model, optimizer, best_model_path, patience=1):\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    num_not_improved = 0\n",
    "    for epoch in range(1, num_epochs):\n",
    "        print()\n",
    "        print(\"#################### Epoch {}: Training Start    ####################\".format(epoch))\n",
    "\n",
    "        train_loss = train(model, train_dataloader)\n",
    "        print('#################### Epoch {}: Training End      ####################'.format(epoch))\n",
    "\n",
    "        print()\n",
    "        print(\"#################### Epoch {}: Validation Start ####################\".format(epoch))\n",
    "\n",
    "        valid_loss, val_targets, val_outputs = valid(model, valid_dataloader)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
    "\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, valid_loss))\n",
    "\n",
    "            checkpoint = {\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'mlb' : mlb.get_params()\n",
    "                    }\n",
    "\n",
    "            save_ckp(checkpoint, best_model_path)\n",
    "            valid_loss_min = valid_loss\n",
    "            num_not_improved = 0\n",
    "        else:\n",
    "            num_not_improved += 1\n",
    "            if num_not_improved >= patience:\n",
    "                print('Not improvement for more than:', num_not_improved)\n",
    "                break\n",
    "            \n",
    "        print(\"#################### Epoch {}: Validation End   ####################\".format(epoch))\n",
    "        print()\n",
    "\n",
    "    print(\"#################### Training finished     ####################\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e10c916",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.856179Z",
     "iopub.status.idle": "2023-12-18T12:21:50.856633Z",
     "shell.execute_reply": "2023-12-18T12:21:50.856425Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.856404Z"
    },
    "executionInfo": {
     "elapsed": 4865,
     "status": "ok",
     "timestamp": 1702260937162,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "Rcg6WbuomeEl",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  trained_model, mlb = load_ckp(best_model_path, model, mlb)\n",
    "except:\n",
    "  print('No saved model found. Need to be train from scratch.')\n",
    "  trained_model = train_model(EPOCHS, train_dataloader, valid_dataloader, model, optimizer,  best_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57bc1e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Evaluating using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef7f6ecf",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.858396Z",
     "iopub.status.idle": "2023-12-18T12:21:50.858865Z",
     "shell.execute_reply": "2023-12-18T12:21:50.858649Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.858626Z"
    },
    "executionInfo": {
     "elapsed": 104385,
     "status": "ok",
     "timestamp": 1702261047724,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "SwCCxjqVHGOO",
    "outputId": "ef2e5975-50fe-4812-eceb-ac38c7c8f068",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231/231 [36:57<00:00,  9.60s/it]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_labels , test_predictions_probs = valid(trained_model, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4378915a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.860303Z",
     "iopub.status.idle": "2023-12-18T12:21:50.860764Z",
     "shell.execute_reply": "2023-12-18T12:21:50.860558Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.860535Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "test_predictions = [[prob > threshold for prob in prob_list] for prob_list in test_predictions_probs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6ffad63",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.861931Z",
     "iopub.status.idle": "2023-12-18T12:21:50.862275Z",
     "shell.execute_reply": "2023-12-18T12:21:50.862124Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.862108Z"
    },
    "executionInfo": {
     "elapsed": 871,
     "status": "ok",
     "timestamp": 1702261050046,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "yxsuBn7pHMCR",
    "outputId": "7d59735e-754c-47b7-fa8b-f079f69b2f47",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mister/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9871134020618557\n",
      "Precision: 0.9953373102525217\n",
      "Recall: 0.9888102893890676\n",
      "F1: 0.9920428209852084\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "      Hotel-Inform       1.00      0.99      0.99      1328\n",
      "     Hotel-Request       0.98      0.96      0.97       292\n",
      " Restaurant-Inform       0.99      0.99      0.99      1323\n",
      "Restaurant-Request       0.99      0.95      0.97       286\n",
      "       general-bye       1.00      1.00      1.00       293\n",
      "     general-greet       0.00      0.00      0.00         6\n",
      "     general-thank       1.00      1.00      1.00       940\n",
      "             other       1.00      0.99      0.99      3307\n",
      "\n",
      "         micro avg       1.00      0.99      0.99      7775\n",
      "         macro avg       0.87      0.86      0.86      7775\n",
      "      weighted avg       1.00      0.99      0.99      7775\n",
      "       samples avg       1.00      0.99      0.99      7775\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mister/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mister/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(test_labels, test_predictions))\n",
    "print('Precision:', precision_score(test_labels, test_predictions, average='weighted'))\n",
    "print('Recall:', recall_score(test_labels, test_predictions, average='weighted'))\n",
    "print('F1:', f1_score(test_labels, test_predictions, average='weighted'))\n",
    "\n",
    "report = classification_report(test_labels, test_predictions, target_names=mlb.classes_)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f8324b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Generating report for LaTex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebe26efe",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.863825Z",
     "iopub.status.idle": "2023-12-18T12:21:50.864276Z",
     "shell.execute_reply": "2023-12-18T12:21:50.864070Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.864047Z"
    },
    "executionInfo": {
     "elapsed": 2651,
     "status": "ok",
     "timestamp": 1702261058885,
     "user": {
      "displayName": "Cristian Bassotto",
      "userId": "01183163487853409209"
     },
     "user_tz": -60
    },
    "id": "NBhDbpkJHOE1",
    "outputId": "5d9e41eb-8ab2-4710-977c-c1f9fb318d9a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, coverage_error, label_ranking_average_precision_score, label_ranking_loss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_metrics_latex_table(model_name, task_number, true_labels, binary_predictions, prediction_probs, target_names):\n",
    "    report = classification_report(true_labels, binary_predictions, target_names=target_names, digits=3, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df['support'] = df['support'].astype(int)\n",
    "    df = df.rename({'precision': r'\\textbf{Precision}', 'recall': r'\\textbf{Recall}', 'f1-score': r'\\textbf{F1-Score}', 'support': r'\\textbf{Support}'}, axis=1)\n",
    "\n",
    "    # Generating additional metrics\n",
    "    accuracy = accuracy_score(true_labels, binary_predictions)\n",
    "    precision, recall, f_score, _ = precision_recall_fscore_support(true_labels, binary_predictions, average='micro')\n",
    "\n",
    "    # Calculating multilabel-specific metrics\n",
    "    coverage_err = coverage_error(true_labels, prediction_probs)\n",
    "    lrap = label_ranking_average_precision_score(true_labels, prediction_probs)\n",
    "    ranking_loss = label_ranking_loss(true_labels, prediction_probs)\n",
    "\n",
    "    # Calculate best/worst/expected values where applicable\n",
    "    # Best possible coverage error is the average number of true labels per instance\n",
    "    best_coverage = true_labels.sum(axis=1).mean()\n",
    "    # The worst case is the total number of labels\n",
    "    worst_coverage = true_labels.shape[1]\n",
    "\n",
    "    # For LRAP, the best value is 1 and the worst is 0. Expected is the baseline or random performance.\n",
    "    best_lrap = 1.0\n",
    "    worst_lrap = 0.0  # This is theoretical; in practice, it's unlikely to get 0\n",
    "\n",
    "    # For ranking loss, the best value is 0. \n",
    "    best_rl = 0.0\n",
    "    # The worst case needs to account for the number of possible incorrect pairings. For each instance, it's the number of true labels times the number of false labels\n",
    "    worst_rl = np.mean([(sum(row) * (len(row) - sum(row))) for row in true_labels])\n",
    "\n",
    "\n",
    "    # Converting to LaTeX table\n",
    "    latex_table = df.to_latex(float_format=\"%.3f\", column_format='|l|c|c|c|c|')\n",
    "    # Removing some stuff from df.to_latex() output\n",
    "    latex_table = latex_table.replace('\\\\toprule\\n ', r'\\hline' + '\\n' + r'\\textbf{Class}') \\\n",
    "                             .replace('\\\\midrule\\n', '') \\\n",
    "                             .replace('\\\\bottomrule', r'\\multicolumn{5}{c}{}\\\\') \\\n",
    "                             .replace('\\\\end{tabular}\\n', '') \\\n",
    "                             .replace(r'\\\\', r'\\\\ \\hline') \\\n",
    "                             .replace('\\nmicro avg','\\\\hline\\nmicro avg')\n",
    "    \n",
    "    # Adding overall metrics\n",
    "    overall_metrics = f\"\"\"\n",
    "{latex_table}\n",
    "\\\\textbf{{Accuracy}}                    & \\\\multicolumn{{4}}{{c|}}{{{accuracy:.3f}}}                                 \\\\\\\\ \\\\hline\n",
    "\\\\textbf{{Overall Precision}}           & \\\\multicolumn{{4}}{{c|}}{{{precision:.3f}}}                                \\\\\\\\ \\\\hline\n",
    "\\\\textbf{{Overall Recall}}              & \\\\multicolumn{{4}}{{c|}}{{{recall:.3f}}}                                   \\\\\\\\ \\\\hline\n",
    "\\\\textbf{{Overall F1-Score}}            & \\\\multicolumn{{4}}{{c|}}{{{f_score:.3f}}}                                  \\\\\\\\ \\\\hline\n",
    "\\\\textbf{{Label Ranking Avg Precision}} & \\\\multicolumn{{4}}{{c|}}{{{lrap:.3f}}}                                    \\\\\\\\ \\\\hline\n",
    "\\\\textbf{{Coverage Error}}              & \\\\multicolumn{{4}}{{c|}}{{{coverage_err:.3f} (worst: {worst_coverage:.3f}, best: {best_coverage:.3f})}}                             \\\\\\\\ \\\\hline\n",
    "\\\\textbf{{Ranking Loss}}                & \\\\multicolumn{{4}}{{c|}}{{{ranking_loss:.3f} (worst: {worst_rl:.3f}, best: {best_rl:.3f})}}                             \\\\\\\\ \\\\hline\n",
    "\\\\end{{tabular}}\n",
    "\"\"\"\n",
    "\n",
    "    # Final LaTeX output with caption and label\n",
    "    final_latex_output = f\"\"\"\n",
    "\\\\begin{{table}}[h]\n",
    "\\\\centering\n",
    "{overall_metrics}\n",
    "\\\\caption{{Metrics Overview of {model_name} Model for Task {task_number}}}\n",
    "\\\\label{{table:{model_name}_metrics_task_{task_number}}}\n",
    "\\\\end{{table}}\n",
    "    \"\"\"\n",
    "\n",
    "    # Print or write to a file\n",
    "    with open('metrics.tex', 'w') as f:\n",
    "        f.write(final_latex_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94054456",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.868534Z",
     "iopub.status.idle": "2023-12-18T12:21:50.868875Z",
     "shell.execute_reply": "2023-12-18T12:21:50.868727Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.868711Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mister/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mister/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "generate_metrics_latex_table(model_name= 'roberta', task_number = '01', true_labels = np.array(test_labels), binary_predictions = test_predictions, prediction_probs = test_predictions_probs, target_names=mlb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee9c50c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Function to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb77838b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse(sentence):\n",
    "    # Tokenize\n",
    "    sentence = nlp(sentence)\n",
    "    # Remove stop words\n",
    "    sentence = \" \".join([token.lemma_ for token in sentence])\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "426bf5da",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T12:21:50.870203Z",
     "iopub.status.idle": "2023-12-18T12:21:50.870555Z",
     "shell.execute_reply": "2023-12-18T12:21:50.870400Z",
     "shell.execute_reply.started": "2023-12-18T12:21:50.870384Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, sentence):\n",
    "    model.eval()\n",
    "    device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "    sentence = parse(sentence)\n",
    "    inputs = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length = max_length,\n",
    "            return_token_type_ids=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            truncation=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "    \n",
    "\n",
    "    input_ids = inputs['input_ids'].to(device, dtype=torch.long)\n",
    "    attention_mask = inputs['attention_mask'].to(device, dtype=torch.long)\n",
    "    token_type_ids = inputs['token_type_ids'].to(device, dtype=torch.long)\n",
    "\n",
    "    outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "    outputs = torch.sigmoid(outputs).cpu().detach().numpy()\n",
    "    threshold = 0.5\n",
    "    outputs = test_predictions = [[prob > threshold for prob in prob_list] for prob_list in outputs ]\n",
    "    \n",
    "    outputs = mlb.inverse_transform(np.array(outputs))\n",
    "    return sentence, outputs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4148846,
     "sourceId": 7178650,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4172201,
     "sourceId": 7229854,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30616,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 266.73919,
   "end_time": "2023-12-18T17:00:49.447437",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-18T16:56:22.708247",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
