{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, Dataset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, normalize\n",
    "from torch import cuda\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support, classification_report, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "from sklearn.metrics import coverage_error, label_ranking_average_precision_score, label_ranking_loss\n",
    "from datasets import load_dataset\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from transformers import AutoTokenizer, RobertaModel\n",
    "from datasets import load_dataset\n",
    "from torch import nn\n",
    "import spacy\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from os.path import exists\n",
    "\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from util import generate_metrics_latex_table\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "if exists('../../word2vec.model'):\n",
    "    word2vec = Word2Vec.load('../../word2vec.model')\n",
    "else:\n",
    "    word2vec = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    word2vec.save('../../word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    # for multi-GPU\n",
    "    torch.cuda.manual_seed_all(seed_value) \n",
    "    # or starting nondeterministic operations in PyTorch\n",
    "    if seed_value is not None:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 13\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_service_list(service_list):\n",
    "    services = set()\n",
    "    if len(service_list) == 0:\n",
    "        services.add('other')\n",
    "    for service in service_list:\n",
    "        if service == 'restaurant':\n",
    "            services.add('restaurant')\n",
    "        elif service == 'hotel':\n",
    "            services.add('hotel')\n",
    "        else:\n",
    "            services.add('other')\n",
    "        if len(services) == 3:\n",
    "            break\n",
    "    return sorted(services)\n",
    "\n",
    "def preprocess_split(dataset, split):\n",
    "    df = dataset[split].to_pandas()\n",
    "    new_df = pd.DataFrame(columns = df.columns)\n",
    "    for i in range(len(df)):\n",
    "        # Taken from notebook, to know which lines to skip\n",
    "        row = df.loc[i]\n",
    "        if not any(set(row.turns['frames'][turn_id]['service']).intersection(['hotel', 'restaurant']) for turn_id,utt in enumerate(row.turns['utterance'])):\n",
    "            continue\n",
    "        new_df.loc[len(new_df)] = row\n",
    "        # new_df.loc[len(new_df) - 1]['services'] = process_service_list(new_df.loc[len(new_df) - 1]['services'])\n",
    "        # for i, frame_service in [frame['service'] for frame in df.loc[i].turns['frames']]:\n",
    "            # df.loc[i].turns['frames']\n",
    "    return new_df\n",
    "\n",
    "def extract_utterance_features(utterance):\n",
    "    doc = nlp(utterance)\n",
    "    \n",
    "    for token in doc:\n",
    "        print(token)\n",
    "    \n",
    "    while True:\n",
    "        pass\n",
    "\n",
    "def extract_feature_df(dataset, default_freqs = {}):\n",
    "    feats_list = []\n",
    "    act_types = []\n",
    "    utterance_list = []\n",
    "    \n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        turns = dataset.loc[i].turns\n",
    "        # print(dataset.loc[i].turns['utterance'])\n",
    "        # print([frame['service'] for frame in dataset.loc[i].turns['frames']])\n",
    "        for utterance, speaker, dialogue_act in zip(turns['utterance'], turns['speaker'], turns['dialogue_acts']):\n",
    "            if speaker == 0: # if it's the user's turn\n",
    "                act_type = dialogue_act['dialog_act']['act_type']\n",
    "                token_pos_list = []\n",
    "                \n",
    "                doc = nlp(utterance)\n",
    "                for token in doc:\n",
    "                    if not token.is_punct and not token.is_stop:\n",
    "                        token_pos_list.append(token.pos_)\n",
    "                \n",
    "                # USING FREQDIST\n",
    "                feats = {}\n",
    "                # feats.update(nltk.FreqDist(nltk.bigrams(token_text_list)))\n",
    "                # feats.update(nltk.FreqDist(nltk.trigrams(token_text_list)))\n",
    "                feats.update(nltk.FreqDist(nltk.bigrams(token_pos_list)))\n",
    "                # feats.update(nltk.FreqDist(nltk.bigrams(token_pos_list)))\n",
    "                # feats.update(nltk.FreqDist(nltk.trigrams(token_pos_list)))\n",
    "                act_types.append(act_type)\n",
    "                \n",
    "                if len(default_freqs) != 0:\n",
    "                    feats = {k : (feats[k] if k in feats else 0) for k in default_freqs.keys()}\n",
    "                feats_list.append(feats)\n",
    "                utterance_list.append(utterance)\n",
    "    \n",
    "    tf_idf = TfidfVectorizer().fit(utterance_list)\n",
    "                    \n",
    "    return tf_idf, utterance_list, pd.DataFrame.from_records(feats_list).fillna(0), act_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: multi_woz_v22/v2.2_active_only\n",
      "Found cached dataset multi_woz_v22 (/Users/pepe/.cache/huggingface/datasets/multi_woz_v22/v2.2_active_only/2.2.0/6719c8b21478299411a0c6fdb7137c3ebab2e6425129af831687fb7851c69eb5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c614c8b30a44cba8b2ee38f2d1d125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6321/6321 [05:42<00:00, 18.48it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 745/745 [00:23<00:00, 31.27it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('multi_woz_v22')\n",
    "\n",
    "train = preprocess_split(dataset, 'train')\n",
    "test = preprocess_split(dataset, 'test')\n",
    "val = preprocess_split(dataset, 'validation')\n",
    "\n",
    "\n",
    "tf_idf, train_utterance_list, train_freqs, train_act_type = extract_feature_df(train)\n",
    "default_freqs = {k : 0 for k in train_freqs.columns}\n",
    "\n",
    "print(len(set(act for act_type in train_act_type for act in act_type))) \n",
    "\n",
    "_, test_utterance_list, test_freqs, test_act_type = extract_feature_df(test, default_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45794, 3420)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=0.001, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=7,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=0.001, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=7,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.001, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.001, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=0.001, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=7,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = XGBClassifier(n_estimators = 100, max_depth = 7, learning_rate = 0.001)\n",
    "rfc = MultiOutputClassifier(rfc)\n",
    "mlb = MultiLabelBinarizer().fit(train_act_type)\n",
    "\n",
    "train_tf_idf_feats = tf_idf.transform(train_utterance_list)\n",
    "train_feats = np.concatenate([train_tf_idf_feats.toarray(), train_freqs.to_numpy()], axis = 1)\n",
    "# train_feats = train_tf_idf_feats.toarray()\n",
    "# train_feats = train_freqs.to_numpy()\n",
    "print(train_feats.shape)\n",
    "\n",
    "rfc.fit(train_feats, mlb.transform(train_act_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.01624049758120249, precision = 0.0, recall = 0.0, f_score = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_tf_idf_feats = tf_idf.transform(test_utterance_list)\n",
    "test_feats = np.concatenate([test_tf_idf_feats.toarray(), test_freqs.to_numpy()], axis = 1)\n",
    "# test_feats = test_tf_idf_feats.toarray()\n",
    "# test_feats = test_freqs.to_numpy()\n",
    "\n",
    "test_act_type_pred = rfc.predict(test_feats)\n",
    "test_act_type_pred_probs = rfc.predict_proba(test_feats)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "acc = accuracy_score(mlb.transform(test_act_type), test_act_type_pred)\n",
    "precision, recall, f_score, _ = precision_recall_fscore_support(mlb.transform(test_act_type), test_act_type_pred, average = 'macro')\n",
    "print(f'acc = {acc}, precision = {precision}, recall = {recall}, f_score = {f_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiOutputClassifier' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      3\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(rfc\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel/01_intent_xgbclassifier.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiOutputClassifier' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "if not os.path.isdir('model'):\n",
    "    os.mkdir('model')\n",
    "torch.save(rfc.state_dict(), f'model/01_intent_xgbclassifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_metrics_latex_table(model_name='XGBClassifier', task_number=1, true_labels=mlb.transform(test_act_type), binary_predictions=test_act_type_pred, prediction_probs=test_act_type_pred_probs, target_names=mlb.classes_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
