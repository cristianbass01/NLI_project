{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert2bert and BART models tested on Kaggle. This is just tests the rule-based approach.\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from slot_filler import map_slot_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = 'facebook/bart-base'\n",
    "save_model_name = TRANSFORMER_MODEL_NAME.split('/')[-1]\n",
    "epochs = 10\n",
    "batch_size = 4\n",
    "learning_rate = 2e-5\n",
    "patience = 2\n",
    "use_history = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_intent_list(intent_list):\n",
    "    intents = set()\n",
    "    if len(intent_list) == 0:\n",
    "        intents.add('other')\n",
    "    for intent in intent_list:\n",
    "        if intent.startswith('Restaurant'):\n",
    "            intents.add(intent)\n",
    "        elif intent.startswith('Hotel'):\n",
    "            intents.add(intent)\n",
    "        elif intent.startswith('general'):\n",
    "            intents.add(intent)\n",
    "        else:\n",
    "            intents.add('other')\n",
    "    # print(f'Original {intent_list}')\n",
    "    # print(f'Modified {list(intents)}')\n",
    "    return list(intents)\n",
    "\n",
    "def process_service_list(service_list):\n",
    "    services = set()\n",
    "    if len(service_list) == 0:\n",
    "        services.add('other')\n",
    "    for service in service_list:\n",
    "        if service == 'restaurant':\n",
    "            services.add('restaurant')\n",
    "        elif service == 'hotel':\n",
    "            services.add('hotel')\n",
    "        else:\n",
    "            services.add('other')\n",
    "        if len(services) == 3:\n",
    "            break\n",
    "    return list(services)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_split(dataset, split):\n",
    "    df = dataset[split].to_pandas()\n",
    "    new_df = pd.DataFrame(columns = df.columns)\n",
    "    for i in range(len(df)):\n",
    "        # Taken from notebook, to know which lines to skip\n",
    "        row = df.loc[i]\n",
    "        if not any(set(row.turns['frames'][turn_id]['service']).intersection(['hotel', 'restaurant']) for turn_id,utt in enumerate(row.turns['utterance'])):\n",
    "            continue\n",
    "        \n",
    "        new_df.loc[len(new_df)] = row\n",
    "        # new_df.loc[len(new_df) - 1]['services'] = process_service_list(new_df.loc[len(new_df) - 1]['services'])\n",
    "        # for i, frame_service in [frame['service'] for frame in df.loc[i].turns['frames']]:\n",
    "            # df.loc[i].turns['frames']\n",
    "    return new_df\n",
    "\n",
    "def extract_token_bio_tags(dataset):\n",
    "    unmapped_string_list = []\n",
    "    mapped_string_list = []\n",
    "    \n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        turns = dataset.loc[i].turns\n",
    "        for j, (utterance, speaker, dialogue_act, frames) in enumerate(zip(turns['utterance'], turns['speaker'], turns['dialogue_acts'], turns['frames'])):\n",
    "\n",
    "            if speaker != 0:\n",
    "                continue\n",
    "            # Skip using dialogue act intents\n",
    "            # if 'other' in process_intent_list(dialogue_act['dialog_act']['act_type']):\n",
    "            #     continue\n",
    "            # Skip using frame services\n",
    "            if 'other' in process_service_list(frames['service']):\n",
    "                continue\n",
    "            \n",
    "            span_info = dialogue_act['span_info']\n",
    "            act_slot_names = span_info['act_slot_name']\n",
    "            act_slot_values = span_info['act_slot_value']\n",
    "            span_starts = span_info['span_start']\n",
    "            span_ends = span_info['span_end']\n",
    "            slots = {slot_name : {'start': start, 'end': end, 'value': value} for slot_name, start, end, value in zip(act_slot_names, span_starts, span_ends, act_slot_values)}\n",
    "\n",
    "\n",
    "            for slot_name in slots:\n",
    "                slot_start, slot_end, slot_value = slots[slot_name]['start'], slots[slot_name]['end'], slots[slot_name]['value']\n",
    "                input_string = utterance[slot_start:slot_end]\n",
    "                output_string = slot_value\n",
    "                \n",
    "                # print(input_string)\n",
    "                # print(output_string)\n",
    "                # print()\n",
    "                \n",
    "                unmapped_string_list.append(input_string)\n",
    "                mapped_string_list.append(output_string)\n",
    "            \n",
    "    return unmapped_string_list, mapped_string_list, mapped_string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: multi_woz_v22/v2.2_active_only\n",
      "Found cached dataset multi_woz_v22 (/home/adrian/.cache/huggingface/datasets/multi_woz_v22/v2.2_active_only/2.2.0/6719c8b21478299411a0c6fdb7137c3ebab2e6425129af831687fb7851c69eb5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9af1273dc1d44efbbbb45f48a64e151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6321/6321 [00:00<00:00, 14388.80it/s]\n",
      "100%|██████████| 762/762 [00:00<00:00, 12724.79it/s]\n",
      "100%|██████████| 745/745 [00:00<00:00, 12580.75it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('multi_woz_v22')\n",
    "\n",
    "train = preprocess_split(dataset, 'train')\n",
    "val = preprocess_split(dataset, 'validation')\n",
    "test = preprocess_split(dataset, 'test')\n",
    "\n",
    "train_unmapped, train_mapped, _ = extract_token_bio_tags(train)\n",
    "val_unmapped, val_mapped, _ = extract_token_bio_tags(val)\n",
    "test_unmapped, test_mapped, test_mapped_string = extract_token_bio_tags(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3241 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3241/3241 [00:00<00:00, 130348.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.984\n",
      "pred = \"same area\", truth = \"north\"\n",
      "pred = \"same area\", truth = \"east\"\n",
      "pred = \"same group of people\", truth = \"5\"\n",
      "pred = \"same day\", truth = \"thursday\"\n",
      "pred = \"same area\", truth = \"centre\"\n",
      "pred = \"same area\", truth = \"north\"\n",
      "pred = \"same area\", truth = \"centre\"\n",
      "pred = \"same number of people\", truth = \"4\"\n",
      "pred = \"same day\", truth = \"tuesday\"\n",
      "pred = \"same day\", truth = \"monday\"\n",
      "pred = \"same day\", truth = \"saturday\"\n",
      "pred = \"same area\", truth = \"east\"\n",
      "pred = \"same day\", truth = \"friday\"\n",
      "pred = \"same amount of people\", truth = \"7\"\n",
      "pred = \"same group of people\", truth = \"6\"\n",
      "pred = \"same area\", truth = \"south\"\n",
      "pred = \"same group of people\", truth = \"2\"\n",
      "pred = \"same day\", truth = \"monday\"\n",
      "pred = \"same day\", truth = \"sunday\"\n",
      "pred = \"same area\", truth = \"east\"\n",
      "pred = \"same group of people\", truth = \"6\"\n",
      "pred = \"same day\", truth = \"sunday\"\n",
      "pred = \"same area\", truth = \"south\"\n",
      "pred = \"same area\", truth = \"centre\"\n",
      "pred = \"same day\", truth = \"monday\"\n",
      "pred = \"same area\", truth = \"centre\"\n",
      "pred = \"same area\", truth = \"centre\"\n",
      "pred = \"same area\", truth = \"south\"\n",
      "pred = \"same group of people\", truth = \"7\"\n",
      "pred = \"same day\", truth = \"saturday\"\n",
      "pred = \"same group of people\", truth = \"7\"\n",
      "pred = \"same day\", truth = \"saturday\"\n",
      "pred = \"same area\", truth = \"east\"\n",
      "pred = \"same area\", truth = \"centre\"\n",
      "pred = \"same day\", truth = \"sunday\"\n",
      "pred = \"same day\", truth = \"monday\"\n",
      "pred = \"same area\", truth = \"east\"\n",
      "pred = \"same day\", truth = \"saturday\"\n",
      "pred = \"same day\", truth = \"wednesday\"\n",
      "pred = \"same area\", truth = \"centre\"\n",
      "pred = \"same day\", truth = \"thursday\"\n",
      "pred = \"same group of people\", truth = \"5\"\n",
      "pred = \"same day\", truth = \"thursday\"\n",
      "pred = \"same day\", truth = \"saturday\"\n",
      "pred = \"same people\", truth = \"3\"\n",
      "pred = \"same area\", truth = \"centre\"\n",
      "pred = \"same area\", truth = \"north\"\n",
      "pred = \"same day\", truth = \"sunday\"\n",
      "pred = \"same group of people\", truth = \"3\"\n",
      "pred = \"same group of people\", truth = \"7\"\n",
      "pred = \"same day\", truth = \"sunday\"\n",
      "pred = \"same area\", truth = \"centre\"\n"
     ]
    }
   ],
   "source": [
    "# transformer = EncoderDecoderModel.from_pretrained('saved_models/MAP_' + save_model_name).cuda()\n",
    "\n",
    "predicted_mapped_string = []\n",
    "for unmapped_string in tqdm(test_unmapped):\n",
    "    predicted_mapped_string.append(map_slot_value(unmapped_string))\n",
    "    \n",
    "test_mapped_string = [s.lower() for s in test_mapped_string]\n",
    "\n",
    "acc = accuracy_score(predicted_mapped_string, test_mapped_string)\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "\n",
    "for pred, test in zip(predicted_mapped_string, test_mapped_string):\n",
    "    if pred != test:\n",
    "        print(f'pred = \\\"{pred}\\\", truth = \\\"{test}\\\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
